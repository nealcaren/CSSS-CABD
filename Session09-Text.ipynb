{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Working with Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "amazon_df = pd.read_csv('https://raw.githubusercontent.com/nealcaren/CSSS-CABD/master/files/amazon_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Positive Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52147</td>\n",
       "      <td>B000EUT8EU</td>\n",
       "      <td>A1RUIFCRZSAQB2</td>\n",
       "      <td>missmoni4x4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1258156800</td>\n",
       "      <td>The best!!!</td>\n",
       "      <td>These are the best \"sugar free\" (non-enriched ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>155382</td>\n",
       "      <td>B000GAT6NG</td>\n",
       "      <td>A32HOM5BOKGXWB</td>\n",
       "      <td>Erica Gott \"foodie\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1233792000</td>\n",
       "      <td>Virgin Coconut Oil</td>\n",
       "      <td>I buy this regularly at Whole Foods for about ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>273760</td>\n",
       "      <td>B000LKTY7Y</td>\n",
       "      <td>A3PRV5LSGOGZRC</td>\n",
       "      <td>Ray A. Van Ostran</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1204934400</td>\n",
       "      <td>Mori-Nu Tofu Lite</td>\n",
       "      <td>Mori-Nu Tofu, Lite, Silken, Firm, 12.3-Ounce B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204752</td>\n",
       "      <td>B001EPPOHO</td>\n",
       "      <td>A3LAYCTGSO1IQR</td>\n",
       "      <td>Purrrfectcat \"purrfectcat\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1328313600</td>\n",
       "      <td>light, soft, stylishly beautiful, delicious!</td>\n",
       "      <td>I usually don't particularly like shortbread c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>203651</td>\n",
       "      <td>B004OQ257M</td>\n",
       "      <td>A1B6O7SAIYG2N0</td>\n",
       "      <td>Jacx \"J.C.\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1316304000</td>\n",
       "      <td>If your already using Splenda but want the B v...</td>\n",
       "      <td>This is good for people that have to be on a s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id   ProductId          UserId                 ProfileName  \\\n",
       "0   52147  B000EUT8EU  A1RUIFCRZSAQB2                 missmoni4x4   \n",
       "1  155382  B000GAT6NG  A32HOM5BOKGXWB         Erica Gott \"foodie\"   \n",
       "2  273760  B000LKTY7Y  A3PRV5LSGOGZRC           Ray A. Van Ostran   \n",
       "3  204752  B001EPPOHO  A3LAYCTGSO1IQR  Purrrfectcat \"purrfectcat\"   \n",
       "4  203651  B004OQ257M  A1B6O7SAIYG2N0                 Jacx \"J.C.\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     0                       0      5  1258156800   \n",
       "1                     0                       0      5  1233792000   \n",
       "2                     7                       9      5  1204934400   \n",
       "3                     0                       0      5  1328313600   \n",
       "4                     0                       0      5  1316304000   \n",
       "\n",
       "                                             Summary  \\\n",
       "0                                        The best!!!   \n",
       "1                                 Virgin Coconut Oil   \n",
       "2                                  Mori-Nu Tofu Lite   \n",
       "3       light, soft, stylishly beautiful, delicious!   \n",
       "4  If your already using Splenda but want the B v...   \n",
       "\n",
       "                                                Text  Positive Review  \n",
       "0  These are the best \"sugar free\" (non-enriched ...                1  \n",
       "1  I buy this regularly at Whole Foods for about ...                1  \n",
       "2  Mori-Nu Tofu, Lite, Silken, Firm, 12.3-Ounce B...                1  \n",
       "3  I usually don't particularly like shortbread c...                1  \n",
       "4  This is good for people that have to be on a s...                1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I bought a Wolfgang Puck sampler and this was certainly one of my favorites, so I ordered a bigger box and have truly been enjoying it.  This is a classic, medium-roast cup of coffee.  It's very smooth, with no bitterness.  I would say that if you enjoy Donut Shop, Tully's Kona, and Caribou, you will like this blend.  The label is adorable and makes me smile when I pop it in the Keurig each morning.\n"
     ]
    }
   ],
   "source": [
    "sample_text = amazon_df['Text'][15]\n",
    "print(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    31933\n",
       "4     7134\n",
       "1     4638\n",
       "3     3742\n",
       "2     2553\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    31933\n",
       "0    18067\n",
       "Name: Positive Review, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df['Positive Review'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Representing text data as Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![bag_of_words](https://raw.githubusercontent.com/nealcaren/CSSS-CABD/master/images/bag_of_words.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Applying bag-of-words to a toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "bards_words =[\"The fool doth think he is wise,\",\n",
    "              \"but the wise man knows himself to be a fool\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "\n",
    "vect.fit(bards_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'be',\n",
       " u'but',\n",
       " u'doth',\n",
       " u'fool',\n",
       " u'he',\n",
       " u'himself',\n",
       " u'is',\n",
       " u'knows',\n",
       " u'man',\n",
       " u'the',\n",
       " u'think',\n",
       " u'to',\n",
       " u'wise']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "bag_of_words = vect.transform(bards_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>be</th>\n",
       "      <th>but</th>\n",
       "      <th>doth</th>\n",
       "      <th>fool</th>\n",
       "      <th>he</th>\n",
       "      <th>himself</th>\n",
       "      <th>is</th>\n",
       "      <th>knows</th>\n",
       "      <th>man</th>\n",
       "      <th>the</th>\n",
       "      <th>think</th>\n",
       "      <th>to</th>\n",
       "      <th>wise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   be  but  doth  fool  he  himself  is  knows  man  the  think  to  wise\n",
       "0   0    0     1     1   1        0   1      0    0    1      1   0     1\n",
       "1   1    1     0     1   0        1   0      1    1    1      0   1     1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You won't ever due this\n",
    "\n",
    "pd.DataFrame( bag_of_words.toarray(), columns=list(vect.get_feature_names()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bag-of-word for product reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=1000, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vectorizer = CountVectorizer(max_features = 1000)\n",
    "\n",
    "tf_vectorizer.fit(amazon_df['Text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vectorizer.get_feature_names()[1501:1510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(tf_vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_train = tf_vectorizer.transform(amazon_df['Text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'00',\n",
       " u'10',\n",
       " u'100',\n",
       " u'11',\n",
       " u'12',\n",
       " u'15',\n",
       " u'16',\n",
       " u'20',\n",
       " u'24',\n",
       " u'25',\n",
       " u'30',\n",
       " u'50',\n",
       " u'able',\n",
       " u'about',\n",
       " u'absolutely',\n",
       " u'acid',\n",
       " u'actually',\n",
       " u'add',\n",
       " u'added',\n",
       " u'adding',\n",
       " u'addition',\n",
       " u'after',\n",
       " u'afternoon',\n",
       " u'aftertaste',\n",
       " u'again',\n",
       " u'ago',\n",
       " u'agree',\n",
       " u'all',\n",
       " u'allergies',\n",
       " u'almond',\n",
       " u'almonds',\n",
       " u'almost',\n",
       " u'along',\n",
       " u'already',\n",
       " u'also',\n",
       " u'alternative',\n",
       " u'although',\n",
       " u'always',\n",
       " u'am',\n",
       " u'amazing',\n",
       " u'amazon',\n",
       " u'amount',\n",
       " u'an',\n",
       " u'and',\n",
       " u'another',\n",
       " u'any',\n",
       " u'anymore',\n",
       " u'anyone',\n",
       " u'anything',\n",
       " u'anyway',\n",
       " u'anywhere',\n",
       " u'apple',\n",
       " u'are',\n",
       " u'area',\n",
       " u'aren',\n",
       " u'aroma',\n",
       " u'around',\n",
       " u'arrived',\n",
       " u'artificial',\n",
       " u'as',\n",
       " u'at',\n",
       " u'ate',\n",
       " u'available',\n",
       " u'avoid',\n",
       " u'away',\n",
       " u'awesome',\n",
       " u'awful',\n",
       " u'baby',\n",
       " u'back',\n",
       " u'bad',\n",
       " u'bag',\n",
       " u'bags',\n",
       " u'baked',\n",
       " u'baking',\n",
       " u'balance',\n",
       " u'bar',\n",
       " u'bars',\n",
       " u'based',\n",
       " u'batch',\n",
       " u'be',\n",
       " u'bean',\n",
       " u'beans',\n",
       " u'beat',\n",
       " u'because',\n",
       " u'become',\n",
       " u'beef',\n",
       " u'been',\n",
       " u'before',\n",
       " u'being',\n",
       " u'believe',\n",
       " u'benefits',\n",
       " u'best',\n",
       " u'better',\n",
       " u'between',\n",
       " u'big',\n",
       " u'bit',\n",
       " u'bite',\n",
       " u'bitter',\n",
       " u'black',\n",
       " u'bland']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(tf_vectorizer.get_feature_names())[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train, amazon_df['Positive Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.79673626,  0.80055202,  0.79545182])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(lr, X_train, amazon_df['Positive Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = pd.DataFrame(lr.coef_[0])\n",
    "len(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1.146513</td>\n",
       "      <td>awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.134461</td>\n",
       "      <td>amazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1.132305</td>\n",
       "      <td>highly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>1.057622</td>\n",
       "      <td>wonderful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0.941916</td>\n",
       "      <td>delicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.904465</td>\n",
       "      <td>yum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0.891726</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>0.886924</td>\n",
       "      <td>glad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>0.881809</td>\n",
       "      <td>thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>0.858350</td>\n",
       "      <td>fantastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.770494</td>\n",
       "      <td>best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>0.756100</td>\n",
       "      <td>perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.730225</td>\n",
       "      <td>beat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>0.705143</td>\n",
       "      <td>loves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0.677579</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>0.664249</td>\n",
       "      <td>unlike</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>0.663512</td>\n",
       "      <td>perfectly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>0.661513</td>\n",
       "      <td>wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>0.656630</td>\n",
       "      <td>finding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>0.650708</td>\n",
       "      <td>favorite</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       word\n",
       "65   1.146513    awesome\n",
       "39   1.134461    amazing\n",
       "409  1.132305     highly\n",
       "979  1.057622  wonderful\n",
       "236  0.941916  delicious\n",
       "998  0.904465        yum\n",
       "292  0.891726  excellent\n",
       "364  0.886924       glad\n",
       "866  0.881809      thank\n",
       "307  0.858350  fantastic\n",
       "91   0.770494       best\n",
       "645  0.756100    perfect\n",
       "82   0.730225       beat\n",
       "508  0.705143      loves\n",
       "867  0.677579     thanks\n",
       "919  0.664249     unlike\n",
       "646  0.663512  perfectly\n",
       "987  0.661513        wow\n",
       "323  0.656630    finding\n",
       "311  0.650708   favorite"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df = pd.DataFrame(lr.coef_).T\n",
    "coef_df['word'] = list(tf_vectorizer.get_feature_names())\n",
    "coef_df.sort_values(0, ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>-1.386423</td>\n",
       "      <td>return</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>-1.217758</td>\n",
       "      <td>unfortunately</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>-1.199489</td>\n",
       "      <td>terrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-1.137127</td>\n",
       "      <td>awful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>-1.131232</td>\n",
       "      <td>horrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>-1.106331</td>\n",
       "      <td>hoping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>-0.949102</td>\n",
       "      <td>disappointed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>-0.939736</td>\n",
       "      <td>okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-0.918957</td>\n",
       "      <td>bland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>-0.887868</td>\n",
       "      <td>however</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>-0.840030</td>\n",
       "      <td>http</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>-0.810236</td>\n",
       "      <td>stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>-0.782186</td>\n",
       "      <td>china</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>-0.768244</td>\n",
       "      <td>stale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>-0.764344</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>-0.707379</td>\n",
       "      <td>star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>-0.673113</td>\n",
       "      <td>expecting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>-0.645080</td>\n",
       "      <td>decent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>-0.629420</td>\n",
       "      <td>rather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>-0.623952</td>\n",
       "      <td>description</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           word\n",
       "722 -1.386423         return\n",
       "917 -1.217758  unfortunately\n",
       "863 -1.199489       terrible\n",
       "66  -1.137127          awful\n",
       "419 -1.131232       horrible\n",
       "418 -1.106331         hoping\n",
       "247 -0.949102   disappointed\n",
       "595 -0.939736           okay\n",
       "99  -0.918957          bland\n",
       "425 -0.887868        however\n",
       "427 -0.840030           http\n",
       "815 -0.810236          stars\n",
       "169 -0.782186          china\n",
       "812 -0.768244          stale\n",
       "594 -0.764344             ok\n",
       "813 -0.707379           star\n",
       "297 -0.673113      expecting\n",
       "233 -0.645080         decent\n",
       "699 -0.629420         rather\n",
       "239 -0.623952    description"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.sort_values(0, ascending=True).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop words: 318\n",
      "Every 10th stopword:\n",
      "['all', 'not', 'one', 'should', 'latterly', 'cannot', 'name', 'each', 'ten', 'beyond', 'mine', 'between', 'full', 'found', 'anything', 'became', 'formerly', 'everyone', 'three', 'anyone', 'was', 'becoming', 'he', 'besides', 'something', 'herein', 'any', 'meanwhile', 'which', 'most', 'whereby', 'rather']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "print(\"Number of stop words: {}\".format(len(ENGLISH_STOP_WORDS)))\n",
    "\n",
    "print(\"Every 10th stopword:\\n{}\".format(list(ENGLISH_STOP_WORDS)[::10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Specifying stop_words=\"english\" uses the built-in list.\n",
    "# We could also augment it and pass our own.\n",
    "tf_vectorizer = CountVectorizer(min_df=.01, \n",
    "                                stop_words=\"english\").fit(amazon_df['Text'])\n",
    "\n",
    "X_train = tf_vectorizer.transform(amazon_df['Text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "586"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, amazon_df['Positive Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[10550,  7517],\n",
       "       [ 3463, 28470]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print accuracy_score(amazon_df['Positive Review'], lr.predict(X_train))\n",
    "confusion_matrix(amazon_df['Positive Review'], lr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>1.244312</td>\n",
       "      <td>highly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.169850</td>\n",
       "      <td>awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.111986</td>\n",
       "      <td>amazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>1.083443</td>\n",
       "      <td>wonderful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>1.009629</td>\n",
       "      <td>glad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>0.964354</td>\n",
       "      <td>thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.959266</td>\n",
       "      <td>delicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.907099</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>0.836119</td>\n",
       "      <td>loves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.824724</td>\n",
       "      <td>fantastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.796876</td>\n",
       "      <td>best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0.767748</td>\n",
       "      <td>perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>0.734567</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.734346</td>\n",
       "      <td>favorite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>0.662333</td>\n",
       "      <td>pleased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0.637845</td>\n",
       "      <td>friends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0.604999</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0.592850</td>\n",
       "      <td>vet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>0.587811</td>\n",
       "      <td>rich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.586683</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       word\n",
       "257  1.244312     highly\n",
       "29   1.169850    awesome\n",
       "18   1.111986    amazing\n",
       "573  1.083443  wonderful\n",
       "229  1.009629       glad\n",
       "520  0.964354      thank\n",
       "147  0.959266  delicious\n",
       "183  0.907099  excellent\n",
       "322  0.836119      loves\n",
       "194  0.824724  fantastic\n",
       "41   0.796876       best\n",
       "393  0.767748    perfect\n",
       "521  0.734567     thanks\n",
       "198  0.734346   favorite\n",
       "401  0.662333    pleased\n",
       "219  0.637845    friends\n",
       "320  0.604999       love\n",
       "555  0.592850        vet\n",
       "443  0.587811       rich\n",
       "239  0.586683      great"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df = pd.DataFrame(lr.coef_).T\n",
    "coef_df['word'] = list(tf_vectorizer.get_feature_names())\n",
    "coef_df.sort_values(0, ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>-1.271479</td>\n",
       "      <td>unfortunately</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>-1.026424</td>\n",
       "      <td>disappointed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>-0.956496</td>\n",
       "      <td>stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>-0.891954</td>\n",
       "      <td>stale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>-0.883145</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>-0.830920</td>\n",
       "      <td>decent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>-0.795837</td>\n",
       "      <td>star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>-0.721214</td>\n",
       "      <td>maybe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>-0.694989</td>\n",
       "      <td>http</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>563</th>\n",
       "      <td>-0.688406</td>\n",
       "      <td>weak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>-0.676369</td>\n",
       "      <td>guess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>342</th>\n",
       "      <td>-0.667466</td>\n",
       "      <td>money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>-0.652506</td>\n",
       "      <td>thought</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.625555</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>-0.606214</td>\n",
       "      <td>wouldn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>-0.588362</td>\n",
       "      <td>expected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>-0.553471</td>\n",
       "      <td>idea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.549821</td>\n",
       "      <td>aftertaste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>-0.534788</td>\n",
       "      <td>overall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>-0.530605</td>\n",
       "      <td>reason</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           word\n",
       "543 -1.271479  unfortunately\n",
       "157 -1.026424   disappointed\n",
       "488 -0.956496          stars\n",
       "485 -0.891954          stale\n",
       "363 -0.883145             ok\n",
       "144 -0.830920         decent\n",
       "486 -0.795837           star\n",
       "332 -0.721214          maybe\n",
       "267 -0.694989           http\n",
       "563 -0.688406           weak\n",
       "243 -0.676369          guess\n",
       "342 -0.667466          money\n",
       "526 -0.652506        thought\n",
       "31  -0.625555            bad\n",
       "579 -0.606214         wouldn\n",
       "186 -0.588362       expected\n",
       "272 -0.553471           idea\n",
       "15  -0.549821     aftertaste\n",
       "377 -0.534788        overall\n",
       "429 -0.530605         reason"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.sort_values(0, ascending=True).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### your turn\n",
    "\n",
    "Go back and spit our dataset into a training and test set. Run and test a model with a large vocabulary one one with a smaller vocabulary. How does fit on the test/train sets compare?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(amazon_df['Text'], amazon_df['Positive Review'], train_size = .8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Big Vocab\n",
    "big_vector = CountVectorizer(max_features  = 5000)\n",
    "\n",
    "big_vector.fit(X_train)\n",
    "tf_train = big_vector.transform(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.865275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[10965,  3515],\n",
       "       [ 1874, 23646]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(tf_train, y_train)\n",
    "\n",
    "print accuracy_score(y_train, lr.predict(tf_train))\n",
    "confusion_matrix(y_train, lr.predict(tf_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8055\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2395, 1192],\n",
       "       [ 753, 5660]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_test = big_vector.transform(X_test)\n",
    "\n",
    "print accuracy_score(y_test, lr.predict(tf_test))\n",
    "confusion_matrix(y_test, lr.predict(tf_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7809\n",
      "0.7707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2034, 1553],\n",
       "       [ 740, 5673]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Small Vocab\n",
    "small_vector = CountVectorizer(stop_words='english',\n",
    "                            min_df=.01)\n",
    "\n",
    "small_vector.fit(X_train)\n",
    "tf_train = small_vector.transform(X_train)\n",
    "\n",
    "lr.fit(tf_train, y_train)\n",
    "\n",
    "print accuracy_score(y_train, lr.predict(tf_train))\n",
    "confusion_matrix(y_train, lr.predict(tf_train))\n",
    "\n",
    "tf_test = small_vector.transform(X_test)\n",
    "\n",
    "print accuracy_score(y_test, lr.predict(tf_test))\n",
    "confusion_matrix(y_test, lr.predict(tf_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Rescaling the Data with tf-idf\n",
    "\\begin{equation*}\n",
    "\\text{tfidf}(w, d) = \\text{tf} \\log\\big(\\frac{N + 1}{N_w + 1}\\big) + 1\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "bards_words =[\"The fool doth think he is wise,\",\n",
    "              \"but the wise man knows himself to be a fool\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "vect.fit(bards_words)\n",
    "bag_of_words = vect.transform(bards_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>be</th>\n",
       "      <th>but</th>\n",
       "      <th>doth</th>\n",
       "      <th>fool</th>\n",
       "      <th>he</th>\n",
       "      <th>himself</th>\n",
       "      <th>is</th>\n",
       "      <th>knows</th>\n",
       "      <th>man</th>\n",
       "      <th>the</th>\n",
       "      <th>think</th>\n",
       "      <th>to</th>\n",
       "      <th>wise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.425677</td>\n",
       "      <td>0.302873</td>\n",
       "      <td>0.425677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.425677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.302873</td>\n",
       "      <td>0.425677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.302873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.364693</td>\n",
       "      <td>0.364693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.259482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364693</td>\n",
       "      <td>0.364693</td>\n",
       "      <td>0.259482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364693</td>\n",
       "      <td>0.259482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         be       but      doth      fool        he   himself        is  \\\n",
       "0  0.000000  0.000000  0.425677  0.302873  0.425677  0.000000  0.425677   \n",
       "1  0.364693  0.364693  0.000000  0.259482  0.000000  0.364693  0.000000   \n",
       "\n",
       "      knows       man       the     think        to      wise  \n",
       "0  0.000000  0.000000  0.302873  0.425677  0.000000  0.302873  \n",
       "1  0.364693  0.364693  0.259482  0.000000  0.364693  0.259482  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame( bag_of_words.toarray(), columns=list(vect.get_feature_names()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(min_df=.01,\n",
    "                stop_words=\"english\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=0.01,\n",
       "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect.fit(amazon_df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tfidf = tfidf_vect.transform(amazon_df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(tfidf, amazon_df['Positive Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[11047,  7020],\n",
       "       [ 3933, 28000]])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print accuracy_score(amazon_df['Positive Review'], lr.predict(tfidf))\n",
    "confusion_matrix(amazon_df['Positive Review'], lr.predict(tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>5.056468</td>\n",
       "      <td>highly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4.999664</td>\n",
       "      <td>best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>4.663251</td>\n",
       "      <td>delicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>4.626625</td>\n",
       "      <td>wonderful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>4.544307</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>4.377871</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.240002</td>\n",
       "      <td>amazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>3.840702</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>3.773116</td>\n",
       "      <td>perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>3.707800</td>\n",
       "      <td>loves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>3.509942</td>\n",
       "      <td>favorite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>3.442428</td>\n",
       "      <td>thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>3.436356</td>\n",
       "      <td>glad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.304006</td>\n",
       "      <td>awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>2.801393</td>\n",
       "      <td>fantastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>2.685495</td>\n",
       "      <td>years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2.611909</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>2.518515</td>\n",
       "      <td>pleased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>2.479076</td>\n",
       "      <td>rich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>2.429870</td>\n",
       "      <td>friends</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       word\n",
       "257  5.056468     highly\n",
       "41   4.999664       best\n",
       "147  4.663251  delicious\n",
       "573  4.626625  wonderful\n",
       "239  4.544307      great\n",
       "320  4.377871       love\n",
       "18   4.240002    amazing\n",
       "183  3.840702  excellent\n",
       "393  3.773116    perfect\n",
       "322  3.707800      loves\n",
       "198  3.509942   favorite\n",
       "520  3.442428      thank\n",
       "229  3.436356       glad\n",
       "29   3.304006    awesome\n",
       "194  2.801393  fantastic\n",
       "583  2.685495      years\n",
       "246  2.611909      happy\n",
       "401  2.518515    pleased\n",
       "443  2.479076       rich\n",
       "219  2.429870    friends"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df = pd.DataFrame(lr.coef_).T\n",
    "coef_df['word'] = list(tf_vectorizer.get_feature_names())\n",
    "coef_df.sort_values(0, ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Bag of words with more than one word (n-grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bards_words:\n",
      "['The fool doth think he is wise,', 'but the wise man knows himself to be a fool']\n"
     ]
    }
   ],
   "source": [
    "print(\"bards_words:\\n{}\".format(bards_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'be',\n",
       " u'be fool',\n",
       " u'but',\n",
       " u'but the',\n",
       " u'doth',\n",
       " u'doth think',\n",
       " u'fool',\n",
       " u'fool doth',\n",
       " u'he',\n",
       " u'he is',\n",
       " u'himself',\n",
       " u'himself to',\n",
       " u'is',\n",
       " u'is wise',\n",
       " u'knows',\n",
       " u'knows himself',\n",
       " u'man',\n",
       " u'man knows',\n",
       " u'the',\n",
       " u'the fool',\n",
       " u'the wise',\n",
       " u'think',\n",
       " u'think he',\n",
       " u'to',\n",
       " u'to be',\n",
       " u'wise',\n",
       " u'wise man']"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(bards_words)\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>be</th>\n",
       "      <th>be fool</th>\n",
       "      <th>but</th>\n",
       "      <th>but the</th>\n",
       "      <th>doth</th>\n",
       "      <th>doth think</th>\n",
       "      <th>fool</th>\n",
       "      <th>fool doth</th>\n",
       "      <th>he</th>\n",
       "      <th>he is</th>\n",
       "      <th>...</th>\n",
       "      <th>man knows</th>\n",
       "      <th>the</th>\n",
       "      <th>the fool</th>\n",
       "      <th>the wise</th>\n",
       "      <th>think</th>\n",
       "      <th>think he</th>\n",
       "      <th>to</th>\n",
       "      <th>to be</th>\n",
       "      <th>wise</th>\n",
       "      <th>wise man</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   be  be fool  but  but the  doth  doth think  fool  fool doth  he  he is  \\\n",
       "0   0        0    0        0     1           1     1          1   1      1   \n",
       "1   1        1    1        1     0           0     1          0   0      0   \n",
       "\n",
       "     ...     man knows  the  the fool  the wise  think  think he  to  to be  \\\n",
       "0    ...             0    1         1         0      1         1   0      0   \n",
       "1    ...             1    1         0         1      0         0   1      1   \n",
       "\n",
       "   wise  wise man  \n",
       "0     1         0  \n",
       "1     1         1  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words = vect.transform(bards_words)\n",
    "\n",
    "pd.DataFrame( bag_of_words.toarray(), columns=list(vect.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'be',\n",
       " u'be fool',\n",
       " u'but',\n",
       " u'but the',\n",
       " u'but the wise',\n",
       " u'doth',\n",
       " u'doth think',\n",
       " u'doth think he',\n",
       " u'fool',\n",
       " u'fool doth',\n",
       " u'fool doth think',\n",
       " u'he',\n",
       " u'he is',\n",
       " u'he is wise',\n",
       " u'himself',\n",
       " u'himself to',\n",
       " u'himself to be',\n",
       " u'is',\n",
       " u'is wise',\n",
       " u'knows',\n",
       " u'knows himself',\n",
       " u'knows himself to',\n",
       " u'man',\n",
       " u'man knows',\n",
       " u'man knows himself',\n",
       " u'the',\n",
       " u'the fool',\n",
       " u'the fool doth',\n",
       " u'the wise',\n",
       " u'the wise man',\n",
       " u'think',\n",
       " u'think he',\n",
       " u'think he is',\n",
       " u'to',\n",
       " u'to be',\n",
       " u'to be fool',\n",
       " u'wise',\n",
       " u'wise man',\n",
       " u'wise man knows']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,3))\n",
    "vect.fit(bards_words)\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.77\n",
      "Best parameters:\n",
      "{'tfidfvectorizer__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(TfidfVectorizer(min_df=.01,\n",
    "                                    stop_words = 'english'), \n",
    "                     LogisticRegression())\n",
    "#\n",
    "param_grid = {\"tfidfvectorizer__ngram_range\": [(1, 1), (1, 2), (1, 3)]}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=3)\n",
    "\n",
    "grid.fit(amazon_df['Text'], amazon_df['Positive Review'])\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_tfidfvectorizer__ngram_range</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.77248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.77230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.77218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_tfidfvectorizer__ngram_range  mean_test_score\n",
       "0                             (1, 1)          0.77248\n",
       "1                             (1, 2)          0.77230\n",
       "2                             (1, 3)          0.77218"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)[['param_tfidfvectorizer__ngram_range','mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cleaning Text on your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "string = '<br> Some random crap.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Some random crap.'"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.replace('<br>', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def clean_string(string):\n",
    "    clean_string = string.replace('<br>', '')\n",
    "    return clean_string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Some random crap.'"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_string('<br> Some random crap.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "amazon_df['clean_text'] = amazon_df['Text'].apply(clean_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    These are the best \"sugar free\" (non-enriched ...\n",
       "1    I buy this regularly at Whole Foods for about ...\n",
       "2    Mori-Nu Tofu, Lite, Silken, Firm, 12.3-Ounce B...\n",
       "3    I usually don't particularly like shortbread c...\n",
       "4    This is good for people that have to be on a s...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def clean_string(string):\n",
    "    clean_string = string.replace('<br>', '')\n",
    "    clean_string = clean_string.replace(\"n't\", \" not\")\n",
    "    return clean_string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def clean_string(string):\n",
    "    clean_string = string.replace('<br>', '')\n",
    "    clean_string = clean_string.replace(\"n't\", \" not\")\n",
    "    \n",
    "    clean_sentence = ''\n",
    "    for word in clean_string.split():\n",
    "        word = word.strip('!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~')\n",
    "        clean_sentence =clean_sentence + ' ' + word\n",
    "    return clean_sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Did that work'"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_string('Did! that work?<br>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'dog'"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'dog'"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'bark'"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('barking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def clean_string(string):\n",
    "    clean_string = string.replace('<br>', '')\n",
    "    clean_string = clean_string.replace(\"n't\", \" not\")\n",
    "    \n",
    "    clean_sentence = u''\n",
    "    for word in clean_string.split():\n",
    "        word = word.strip('!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~')\n",
    "        try:\n",
    "            word = stemmer.stem(word)\n",
    "        except:\n",
    "            word = word\n",
    "        try:\n",
    "            clean_sentence =clean_sentence + ' ' + word\n",
    "        except:\n",
    "            print word\n",
    "    return clean_sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u' the dog went run with other dog'"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_string('The dog went running with other dogs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organic\n",
      "185F\n",
      "185F\n",
      "\n",
      "105F\n",
      "ENERGY\n",
      "Typhoo\n",
      "Salt\n",
      "brl&eacute;e\n",
      "brl&eacute;e\n",
      "Quaker\n",
      "href=\"http://www.amazon.com/gp/product/B004KJXSHO\">Keurig\n",
      "\n",
      "Brand\n",
      "Brand\n",
      "Marzano\n",
      "pt&eacute\n",
      "pt&eacute\n",
      "aykur\n",
      "90\n",
      "2\n",
      "7-year-old\n",
      "7-year-old\n",
      "2\n",
      "1\n",
      "ENERGY\n",
      "60/k-cup\n",
      "AvoDerm\n",
      "AvoDerm\n",
      "AvoDerm\n",
      "AvoDerm\n",
      "AvoDerm\n",
      "58\n",
      "ENERGY\n",
      "ENERGY\n",
      "Eatin'\n",
      "\n",
      "99\n",
      "\n",
      "Mountain\n",
      "VIA\n",
      "96\n",
      "12\n",
      "6\n",
      "8\n",
      "1.37\n",
      "barbecue\n",
      "thinkThin\n",
      "thinkThin\n",
      "Eatin'\n",
      "104\n",
      "400\n",
      "200\n",
      "180\n",
      "103\n",
      "\n",
      "pt&eacute\n",
      "Rverie\n",
      "s\n",
      "DecoBros</a\n",
      "Kelloggs\n",
      "href=\"http://www.amazon.com/gp/product/B000G72D70\">swissgold\n",
      "500\n",
      "350\n",
      "Organic\n",
      "\n",
      "\n",
      "1\n",
      "8-ounce\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "400.<br\n",
      "Water\n",
      "Jel\n",
      "Jel\n",
      "Jel\n",
      "Jel\n",
      "Jel\n",
      "Jel\n",
      "\n",
      "\n",
      "OwnOrganics\n",
      "Nol\n",
      "Foods,\n",
      "AUTOSPOUT\n",
      "ENERGY\n",
      "VIA\n",
      "\n",
      "\n",
      "113F\n",
      "113F\n",
      "50F.<br\n",
      "Nioise\n",
      "VIA\n",
      "ENERGY\n",
      "Own\n",
      "\n",
      "ENERGY\n",
      "brl&eacute;e\n",
      "\n",
      "2010\n",
      "Almond\n",
      "NutraSweet/aspartame\n",
      "175\n",
      "\n",
      "\n",
      "ENERGY\n",
      "Gold\n",
      "pt&eacute\n",
      "WellPet\n",
      "WELLNESS\n",
      "WELLNESS\n",
      "Program\n",
      "ENERGY\n",
      "href=\"http://www.amazon.com/gp/product/B002WWVDK0\">Sexergy\n",
      "Starbucks\n",
      "Caribou\n",
      "Coffee\n",
      "House\n",
      "Folgers\n",
      "O'Clock\n",
      "Starbucks\n",
      "Caribou\n",
      "Coffee\n",
      "Mountain\n",
      "VIA\n",
      "25\n",
      "OwnOrganics\n",
      "Brand\n",
      "Brand\n",
      "ENERGY\n",
      "ENERGY\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     these are the best sugar free non-enrich whea...\n",
       "1     i buy this regular at whole food for about 30...\n",
       "2     mori-nu tofu lite silken firm 12.3-ounc box p...\n",
       "3     i usual do not particular like shortbread coo...\n",
       "4     this is good for peopl that have to be on a s...\n",
       "5     my uncl bilbo alway woke up to a hearti bowl ...\n",
       "6     this is the herbal remedi of choic for those ...\n",
       "7     just receiv these today and was stun to see t...\n",
       "8     best coffe ever after tast these fresh ground...\n",
       "9     i have been buy ella sinc my son was 6 month ...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df['clean_text'] = amazon_df['Text'].apply(clean_string)\n",
    "\n",
    "amazon_df['clean_text'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,1), min_df=.01, max_df=.5, stop_words = 'english')\n",
    "vect.fit(amazon_df['clean_text'])\n",
    "\n",
    "clean_tf = vect.transform(amazon_df['clean_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(clean_tf, amazon_df['Positive Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[10755,  7312],\n",
       "       [ 3308, 28625]])"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print accuracy_score(amazon_df['Positive Review'], lr.predict(clean_tf))\n",
    "confusion_matrix(amazon_df['Positive Review'], lr.predict(clean_tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Naive Bayes\n",
    "\n",
    "$$\n",
    "\\frac{P(L_1~|~{\\rm features})}{P(L_2~|~{\\rm features})} = \\frac{P({\\rm features}~|~L_1)}{P({\\rm features}~|~L_2)}\\frac{P(L_1)}{P(L_2)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(min_df=.01, \n",
    "                                stop_words=\"english\").fit(amazon_df['Text'])\n",
    "\n",
    "X_train_tf = tf_vectorizer.transform(amazon_df['Text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train_tf, amazon_df['Positive Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5908, 12159],\n",
       "       [ 1146, 30787]])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print accuracy_score(amazon_df['Positive Review'], nb.predict(tfidf))\n",
    "confusion_matrix(amazon_df['Positive Review'], nb.predict(tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>-3.739278</td>\n",
       "      <td>-3.992257</td>\n",
       "      <td>br</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>-5.162631</td>\n",
       "      <td>-4.347369</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>-5.434581</td>\n",
       "      <td>-4.526610</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>-4.507674</td>\n",
       "      <td>-4.589347</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>-4.335316</td>\n",
       "      <td>-4.624931</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>-4.862358</td>\n",
       "      <td>-4.640573</td>\n",
       "      <td>tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>-4.489168</td>\n",
       "      <td>-4.655693</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>-4.565865</td>\n",
       "      <td>-4.735544</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>-4.744796</td>\n",
       "      <td>-4.811386</td>\n",
       "      <td>just</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>-4.513256</td>\n",
       "      <td>-4.847411</td>\n",
       "      <td>taste</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1     word\n",
       "58  -3.739278 -3.992257       br\n",
       "239 -5.162631 -4.347369    great\n",
       "320 -5.434581 -4.526610     love\n",
       "235 -4.507674 -4.589347     good\n",
       "303 -4.335316 -4.624931     like\n",
       "515 -4.862358 -4.640573      tea\n",
       "101 -4.489168 -4.655693   coffee\n",
       "415 -4.565865 -4.735544  product\n",
       "286 -4.744796 -4.811386     just\n",
       "510 -4.513256 -4.847411    taste"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_probs = pd.DataFrame(nb.feature_log_prob_).T\n",
    "nb_probs['word'] = tf_vectorizer.get_feature_names()\n",
    "nb_probs.sort_values(1, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>-3.739278</td>\n",
       "      <td>-3.992257</td>\n",
       "      <td>br</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>-4.335316</td>\n",
       "      <td>-4.624931</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>-4.489168</td>\n",
       "      <td>-4.655693</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>-4.507674</td>\n",
       "      <td>-4.589347</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>-4.513256</td>\n",
       "      <td>-4.847411</td>\n",
       "      <td>taste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>-4.565865</td>\n",
       "      <td>-4.735544</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>-4.695297</td>\n",
       "      <td>-4.858587</td>\n",
       "      <td>flavor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>-4.744796</td>\n",
       "      <td>-4.811386</td>\n",
       "      <td>just</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>-4.862358</td>\n",
       "      <td>-4.640573</td>\n",
       "      <td>tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>-5.069015</td>\n",
       "      <td>-5.375158</td>\n",
       "      <td>don</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1     word\n",
       "58  -3.739278 -3.992257       br\n",
       "303 -4.335316 -4.624931     like\n",
       "101 -4.489168 -4.655693   coffee\n",
       "235 -4.507674 -4.589347     good\n",
       "510 -4.513256 -4.847411    taste\n",
       "415 -4.565865 -4.735544  product\n",
       "208 -4.695297 -4.858587   flavor\n",
       "286 -4.744796 -4.811386     just\n",
       "515 -4.862358 -4.640573      tea\n",
       "163 -5.069015 -5.375158      don"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_probs.sort_values(0, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Topic Modeling and Document Clustering\n",
    "#### Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_features=5000, \n",
    "                       max_df=.5,\n",
    "                       stop_words = 'english', \n",
    "                      min_df = .01)\n",
    "\n",
    "X_train = vect.fit_transform(amazon_df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda_model = LatentDirichletAllocation(n_topics=10,\n",
    "                                      learning_method = 'batch',\n",
    "                                      max_iter=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='batch', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=25, mean_change_tol=0.001,\n",
       "             n_jobs=1, n_topics=10, perp_tol=0.1, random_state=None,\n",
       "             topic_word_prior=None, total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "document_topics = lda_model.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda.components_.shape: (10, 586)\n"
     ]
    }
   ],
   "source": [
    "print(\"lda.components_.shape: {}\".format(lda_model.components_.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag, treats, chips, dog, like, treat, dogs, just, size, small\n",
      "br, product, amazon, com, www, http, gp, href, pack, ounce\n",
      "amazon, product, price, order, store, great, buy, box, good, ordered\n",
      "like, flavor, taste, just, good, drink, really, sweet, flavors, sugar\n",
      "food, cat, dog, cats, eat, old, like, chicken, foods, loves\n",
      "use, water, product, just, like, great, make, oil, salt, butter\n",
      "great, free, snack, good, gluten, love, bars, healthy, fat, eat\n",
      "tea, green, teas, flavor, black, like, drink, taste, ginger, good\n",
      "coffee, cup, like, cups, flavor, good, taste, strong, blend, beans\n",
      "chocolate, like, taste, cookies, good, milk, hot, sauce, flavor, just\n",
      "yummy, yes, years, year, www, wrong, wouldn, worth, world, works\n"
     ]
    }
   ],
   "source": [
    "tm_df = pd.DataFrame(lda_model.components_).T\n",
    "tm_df['words'] = vect.get_feature_names()\n",
    "for k in tm_df.keys():\n",
    "    print ', '.join(tm_df.sort_values(by=k, ascending=False)['words'].tolist()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(document_topics, amazon_df['Positive Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1682, 16385],\n",
       "       [ 1562, 30371]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print accuracy_score(amazon_df['Positive Review'], lr.predict(document_topics))\n",
    "confusion_matrix(amazon_df['Positive Review'], lr.predict(document_topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='batch', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=25, mean_change_tol=0.001,\n",
       "             n_jobs=1, n_topics=50, perp_tol=0.1, random_state=None,\n",
       "             topic_word_prior=None, total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model_50 = LatentDirichletAllocation(n_topics=50,\n",
    "                                      learning_method = 'batch',\n",
    "                                      max_iter=25)\n",
    "lda_model_50.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_topics_50 = lda_model_50.transform(X_train)\n",
    "\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(document_topics_50, amazon_df['Positive Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 7002, 11065],\n",
       "       [ 3930, 28003]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print accuracy_score(amazon_df['Positive Review'], lr.predict(document_topics_50))\n",
    "confusion_matrix(amazon_df['Positive Review'], lr.predict(document_topics_50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "popcorn, corn, packs, pop, bowl, just, great, like, taste, use\n",
      "bottle, energy, red, powder, bottles, drinks, gives, oz, drink, caffeine\n",
      "food, dog, foods, dry, feed, ingredients, pet, dogs, quality, diet\n",
      "eat, food, cats, cat, chicken, like, picky, ate, eats, just\n",
      "product, recommend, highly, great, excellent, recommended, good, taste, love, definitely\n",
      "products, quality, company, fast, product, items, service, high, shipping, delivery\n",
      "tea, teas, drink, like, good, cup, taste, iced, flavor, love\n",
      "bought, try, reviews, great, thought, decided, read, thanks, fantastic, did\n",
      "use, oil, coconut, cooking, cook, great, recipe, used, love, taste\n",
      "vanilla, beans, ground, starbucks, french, coffee, aroma, taste, flavored, smell\n",
      "chocolate, dark, cocoa, hot, milk, rich, taste, sweet, like, best\n",
      "green, white, black, caffeine, color, decaf, mild, high, fresh, compared\n",
      "low, diet, pasta, version, regular, alternative, jar, calorie, difference, great\n",
      "coffee, blend, strong, roast, bold, like, bitter, smooth, taste, dark\n",
      "chips, potato, chip, bag, like, good, taste, flavor, crunch, great\n",
      "product, using, used, use, works, ve, does, just, don, like\n",
      "organic, rice, brown, color, non, foods, texture, tasty, delicious, comes\n",
      "ingredients, natural, cinnamon, soy, ingredient, list, contains, contain, label, artificial\n",
      "salt, salty, pepper, fish, formula, taste, sodium, use, just, love\n",
      "weight, help, problems, stomach, started, teeth, blue, vet, issues, recommended\n",
      "dog, treats, dogs, treat, loves, love, chew, small, like, great\n",
      "cat, cans, canned, seen, case, grain, ve, food, care, formula\n",
      "sweet, taste, honey, like, liked, flavor, good, stars, bit, light\n",
      "br, review, ll, want, people, note, just, new, thing, know\n",
      "add, milk, cream, ice, make, cold, mix, just, adding, half\n",
      "years, old, year, ve, ago, months, month, past, new, couple\n",
      "order, ordered, received, amazon, arrived, product, item, time, box, ordering\n",
      "like, taste, don, good, just, really, bad, tastes, think, know\n",
      "flavor, flavored, fan, nice, original, good, favorite, big, strong, try\n",
      "free, mix, gluten, bread, wheat, good, baking, make, best, products\n",
      "price, great, amazon, save, good, deal, shipping, subscribe, cost, buy\n",
      "tried, love, flavors, ve, favorite, different, best, variety, absolutely, try\n",
      "fruit, juice, syrup, ginger, lemon, apple, dried, like, taste, sweet\n",
      "cookies, perfect, cookie, kids, soft, love, just, great, like, taste\n",
      "box, bag, package, open, packaging, small, size, plastic, inside, opened\n",
      "store, amazon, local, stores, grocery, buy, available, love, online, stock\n",
      "snack, bars, healthy, bar, great, protein, good, eat, kind, taste\n",
      "sauce, hot, spicy, spice, heat, like, just, good, flavor, great\n",
      "amazon, pack, com, product, www, http, gp, href, ounce, 12\n",
      "time, long, candy, loved, family, hard, gift, friends, great, goes\n",
      "bags, buy, buying, bag, money, bought, pound, size, bulk, waste\n",
      "sugar, jerky, beef, meat, real, sweet, texture, added, like, pieces\n",
      "cereal, loves, baby, son, daughter, wife, oatmeal, husband, likes, breakfast\n",
      "butter, peanut, soup, nuts, creamy, like, great, eat, good, texture\n",
      "day, just, got, days, took, didn, night, time, start, little\n",
      "calories, fat, serving, fiber, high, low, sodium, protein, crackers, content\n",
      "coffee, cup, cups, keurig, machine, good, use, maker, instant, great\n",
      "water, drink, drinking, taste, hot, day, tastes, just, added, bottle\n",
      "easy, cheese, make, minutes, just, little, cut, quick, time, makes\n",
      "brand, stuff, best, better, good, brands, ve, tried, expensive, far\n",
      "yummy, yes, years, year, www, wrong, wouldn, worth, world, works\n"
     ]
    }
   ],
   "source": [
    "tm_df = pd.DataFrame(lda_model_50.components_).T\n",
    "tm_df['words'] = vect.get_feature_names()\n",
    "for k in tm_df.keys():\n",
    "    print ', '.join(tm_df.sort_values(by=k, ascending=False)['words'].tolist()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'document_topics_50' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-e1b843b6c533>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdocument_topics_50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'document_topics_50' is not defined"
     ]
    }
   ],
   "source": [
    "document_topics_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
