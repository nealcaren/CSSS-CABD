{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Working with Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "amazon_df = pd.read_csv('https://raw.githubusercontent.com/nealcaren/CSSS-CABD/master/files/amazon_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>Positive Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52147</td>\n",
       "      <td>B000EUT8EU</td>\n",
       "      <td>A1RUIFCRZSAQB2</td>\n",
       "      <td>missmoni4x4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1258156800</td>\n",
       "      <td>The best!!!</td>\n",
       "      <td>These are the best \"sugar free\" (non-enriched ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>155382</td>\n",
       "      <td>B000GAT6NG</td>\n",
       "      <td>A32HOM5BOKGXWB</td>\n",
       "      <td>Erica Gott \"foodie\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1233792000</td>\n",
       "      <td>Virgin Coconut Oil</td>\n",
       "      <td>I buy this regularly at Whole Foods for about ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>273760</td>\n",
       "      <td>B000LKTY7Y</td>\n",
       "      <td>A3PRV5LSGOGZRC</td>\n",
       "      <td>Ray A. Van Ostran</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1204934400</td>\n",
       "      <td>Mori-Nu Tofu Lite</td>\n",
       "      <td>Mori-Nu Tofu, Lite, Silken, Firm, 12.3-Ounce B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>204752</td>\n",
       "      <td>B001EPPOHO</td>\n",
       "      <td>A3LAYCTGSO1IQR</td>\n",
       "      <td>Purrrfectcat \"purrfectcat\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1328313600</td>\n",
       "      <td>light, soft, stylishly beautiful, delicious!</td>\n",
       "      <td>I usually don't particularly like shortbread c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>203651</td>\n",
       "      <td>B004OQ257M</td>\n",
       "      <td>A1B6O7SAIYG2N0</td>\n",
       "      <td>Jacx \"J.C.\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1316304000</td>\n",
       "      <td>If your already using Splenda but want the B v...</td>\n",
       "      <td>This is good for people that have to be on a s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Id   ProductId          UserId                 ProfileName  \\\n",
       "0   52147  B000EUT8EU  A1RUIFCRZSAQB2                 missmoni4x4   \n",
       "1  155382  B000GAT6NG  A32HOM5BOKGXWB         Erica Gott \"foodie\"   \n",
       "2  273760  B000LKTY7Y  A3PRV5LSGOGZRC           Ray A. Van Ostran   \n",
       "3  204752  B001EPPOHO  A3LAYCTGSO1IQR  Purrrfectcat \"purrfectcat\"   \n",
       "4  203651  B004OQ257M  A1B6O7SAIYG2N0                 Jacx \"J.C.\"   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     0                       0      5  1258156800   \n",
       "1                     0                       0      5  1233792000   \n",
       "2                     7                       9      5  1204934400   \n",
       "3                     0                       0      5  1328313600   \n",
       "4                     0                       0      5  1316304000   \n",
       "\n",
       "                                             Summary  \\\n",
       "0                                        The best!!!   \n",
       "1                                 Virgin Coconut Oil   \n",
       "2                                  Mori-Nu Tofu Lite   \n",
       "3       light, soft, stylishly beautiful, delicious!   \n",
       "4  If your already using Splenda but want the B v...   \n",
       "\n",
       "                                                Text  Positive Review  \n",
       "0  These are the best \"sugar free\" (non-enriched ...                1  \n",
       "1  I buy this regularly at Whole Foods for about ...                1  \n",
       "2  Mori-Nu Tofu, Lite, Silken, Firm, 12.3-Ounce B...                1  \n",
       "3  I usually don't particularly like shortbread c...                1  \n",
       "4  This is good for people that have to be on a s...                1  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I bought a Wolfgang Puck sampler and this was certainly one of my favorites, so I ordered a bigger box and have truly been enjoying it.  This is a classic, medium-roast cup of coffee.  It's very smooth, with no bitterness.  I would say that if you enjoy Donut Shop, Tully's Kona, and Caribou, you will like this blend.  The label is adorable and makes me smile when I pop it in the Keurig each morning.\n"
     ]
    }
   ],
   "source": [
    "sample_text = amazon_df['Text'][15]\n",
    "print(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    31933\n",
       "4     7134\n",
       "1     4638\n",
       "3     3742\n",
       "2     2553\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    31933\n",
       "0    18067\n",
       "Name: Positive Review, dtype: int64"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df['Positive Review'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Representing text data as Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![bag_of_words](https://raw.githubusercontent.com/nealcaren/CSSS-CABD/master/images/bag_of_words.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "#### Applying bag-of-words to a toy dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "bards_words =[\"The fool doth think he is wise,\",\n",
    "              \"but the wise man knows himself to be a fool\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "\n",
    "vect.fit(bards_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vect.vocabulary_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'be',\n",
       " u'but',\n",
       " u'doth',\n",
       " u'fool',\n",
       " u'he',\n",
       " u'himself',\n",
       " u'is',\n",
       " u'knows',\n",
       " u'man',\n",
       " u'the',\n",
       " u'think',\n",
       " u'to',\n",
       " u'wise']"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "bag_of_words = vect.transform(bards_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>be</th>\n",
       "      <th>but</th>\n",
       "      <th>doth</th>\n",
       "      <th>fool</th>\n",
       "      <th>he</th>\n",
       "      <th>himself</th>\n",
       "      <th>is</th>\n",
       "      <th>knows</th>\n",
       "      <th>man</th>\n",
       "      <th>the</th>\n",
       "      <th>think</th>\n",
       "      <th>to</th>\n",
       "      <th>wise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   be  but  doth  fool  he  himself  is  knows  man  the  think  to  wise\n",
       "0   0    0     1     1   1        0   1      0    0    1      1   0     1\n",
       "1   1    1     0     1   0        1   0      1    1    1      0   1     1"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You won't ever due this\n",
    "\n",
    "pd.DataFrame( bag_of_words.toarray(), columns=list(vect.get_feature_names()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bag-of-word for product reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=5000, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vectorizer = CountVectorizer(max_features = 5000)\n",
    "\n",
    "tf_vectorizer.fit(amazon_df['Text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'equal',\n",
       " u'equally',\n",
       " u'equipment',\n",
       " u'equivalent',\n",
       " u'error',\n",
       " u'erythritol',\n",
       " u'escapes',\n",
       " u'especially',\n",
       " u'espresso']"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vectorizer.get_feature_names()[1501:1510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(tf_vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "X_train = tf_vectorizer.transform(amazon_df['Text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(X_train, amazon_df['Positive Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.85654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[13378,  4689],\n",
       "       [ 2484, 29449]])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "print accuracy_score(amazon_df['Positive Review'], lr.predict(X_train))\n",
    "confusion_matrix(amazon_df['Positive Review'], lr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3200</th>\n",
       "      <td>2.059872</td>\n",
       "      <td>phenomenal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>1.840226</td>\n",
       "      <td>amazed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3339</th>\n",
       "      <td>1.816009</td>\n",
       "      <td>prescription</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3800</th>\n",
       "      <td>1.773014</td>\n",
       "      <td>scientific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3391</th>\n",
       "      <td>1.747569</td>\n",
       "      <td>profit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2143</th>\n",
       "      <td>1.739937</td>\n",
       "      <td>hooked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4818</th>\n",
       "      <td>1.662003</td>\n",
       "      <td>watched</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>1.629392</td>\n",
       "      <td>prescribed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>1.617551</td>\n",
       "      <td>exquisite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3989</th>\n",
       "      <td>1.516259</td>\n",
       "      <td>skeptical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944</th>\n",
       "      <td>1.507159</td>\n",
       "      <td>compact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3385</th>\n",
       "      <td>1.482318</td>\n",
       "      <td>producing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>1.448724</td>\n",
       "      <td>asking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134</th>\n",
       "      <td>1.421510</td>\n",
       "      <td>pastas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>1.411164</td>\n",
       "      <td>healing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>1.408858</td>\n",
       "      <td>availability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1647</th>\n",
       "      <td>1.399482</td>\n",
       "      <td>fermentation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>1.379615</td>\n",
       "      <td>cows</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4035</th>\n",
       "      <td>1.370374</td>\n",
       "      <td>sneak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3581</th>\n",
       "      <td>1.356365</td>\n",
       "      <td>relaxed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0          word\n",
       "3200  2.059872    phenomenal\n",
       "226   1.840226        amazed\n",
       "3339  1.816009  prescription\n",
       "3800  1.773014    scientific\n",
       "3391  1.747569        profit\n",
       "2143  1.739937        hooked\n",
       "4818  1.662003       watched\n",
       "3338  1.629392    prescribed\n",
       "1572  1.617551     exquisite\n",
       "3989  1.516259     skeptical\n",
       "944   1.507159       compact\n",
       "3385  1.482318     producing\n",
       "316   1.448724        asking\n",
       "3134  1.421510        pastas\n",
       "2057  1.411164       healing\n",
       "345   1.408858  availability\n",
       "1647  1.399482  fermentation\n",
       "1077  1.379615          cows\n",
       "4035  1.370374         sneak\n",
       "3581  1.356365       relaxed"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df = pd.DataFrame(lr.coef_).T\n",
    "coef_df['word'] = list(tf_vectorizer.get_feature_names())\n",
    "coef_df.sort_values(0, ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3567</th>\n",
       "      <td>-2.137325</td>\n",
       "      <td>refunded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>-2.041797</td>\n",
       "      <td>deceptive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>-1.896320</td>\n",
       "      <td>disappointment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1309</th>\n",
       "      <td>-1.813925</td>\n",
       "      <td>disappointing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4183</th>\n",
       "      <td>-1.681796</td>\n",
       "      <td>starving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4675</th>\n",
       "      <td>-1.665520</td>\n",
       "      <td>undrinkable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4935</th>\n",
       "      <td>-1.658926</td>\n",
       "      <td>worst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3468</th>\n",
       "      <td>-1.652188</td>\n",
       "      <td>question</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>-1.641353</td>\n",
       "      <td>disgusting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2781</th>\n",
       "      <td>-1.637851</td>\n",
       "      <td>misleading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>-1.631210</td>\n",
       "      <td>bin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3648</th>\n",
       "      <td>-1.628533</td>\n",
       "      <td>returns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>-1.627562</td>\n",
       "      <td>groceries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>-1.570735</td>\n",
       "      <td>bummer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>-1.505195</td>\n",
       "      <td>drizzled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>-1.495087</td>\n",
       "      <td>fellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>-1.484996</td>\n",
       "      <td>conclusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>-1.469382</td>\n",
       "      <td>artificially</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>-1.441959</td>\n",
       "      <td>cancelled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>-1.414470</td>\n",
       "      <td>choke</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0            word\n",
       "3567 -2.137325        refunded\n",
       "1186 -2.041797       deceptive\n",
       "1310 -1.896320  disappointment\n",
       "1309 -1.813925   disappointing\n",
       "4183 -1.681796        starving\n",
       "4675 -1.665520     undrinkable\n",
       "4935 -1.658926           worst\n",
       "3468 -1.652188        question\n",
       "1322 -1.641353      disgusting\n",
       "2781 -1.637851      misleading\n",
       "485  -1.631210             bin\n",
       "3648 -1.628533         returns\n",
       "1971 -1.627562       groceries\n",
       "633  -1.570735          bummer\n",
       "1391 -1.505195        drizzled\n",
       "1642 -1.495087          fellow\n",
       "977  -1.484996      conclusion\n",
       "310  -1.469382    artificially\n",
       "689  -1.441959       cancelled\n",
       "841  -1.414470           choke"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df.sort_values(0, ascending=True).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Stop-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stop words: 318\n",
      "Every 10th stopword:\n",
      "['all', 'not', 'one', 'should', 'latterly', 'cannot', 'name', 'each', 'ten', 'beyond', 'mine', 'between', 'full', 'found', 'anything', 'became', 'formerly', 'everyone', 'three', 'anyone', 'was', 'becoming', 'he', 'besides', 'something', 'herein', 'any', 'meanwhile', 'which', 'most', 'whereby', 'rather']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "print(\"Number of stop words: {}\".format(len(ENGLISH_STOP_WORDS)))\n",
    "\n",
    "print(\"Every 10th stopword:\\n{}\".format(list(ENGLISH_STOP_WORDS)[::10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Specifying stop_words=\"english\" uses the built-in list.\n",
    "# We could also augment it and pass our own.\n",
    "tf_vectorizer = CountVectorizer(min_df=.01, \n",
    "                                stop_words=\"english\").fit(amazon_df['Text'])\n",
    "\n",
    "X_train = tf_vectorizer.transform(amazon_df['Text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "586"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, amazon_df['Positive Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7804\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[10550,  7517],\n",
       "       [ 3463, 28470]])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print accuracy_score(amazon_df['Positive Review'], lr.predict(X_train))\n",
    "confusion_matrix(amazon_df['Positive Review'], lr.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>1.244312</td>\n",
       "      <td>highly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.169850</td>\n",
       "      <td>awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1.111986</td>\n",
       "      <td>amazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>1.083443</td>\n",
       "      <td>wonderful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>1.009629</td>\n",
       "      <td>glad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>0.964354</td>\n",
       "      <td>thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.959266</td>\n",
       "      <td>delicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.907099</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>0.836119</td>\n",
       "      <td>loves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>0.824724</td>\n",
       "      <td>fantastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.796876</td>\n",
       "      <td>best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0.767748</td>\n",
       "      <td>perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>0.734567</td>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.734346</td>\n",
       "      <td>favorite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>0.662333</td>\n",
       "      <td>pleased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>0.637845</td>\n",
       "      <td>friends</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0.604999</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0.592850</td>\n",
       "      <td>vet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>0.587811</td>\n",
       "      <td>rich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.586683</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       word\n",
       "257  1.244312     highly\n",
       "29   1.169850    awesome\n",
       "18   1.111986    amazing\n",
       "573  1.083443  wonderful\n",
       "229  1.009629       glad\n",
       "520  0.964354      thank\n",
       "147  0.959266  delicious\n",
       "183  0.907099  excellent\n",
       "322  0.836119      loves\n",
       "194  0.824724  fantastic\n",
       "41   0.796876       best\n",
       "393  0.767748    perfect\n",
       "521  0.734567     thanks\n",
       "198  0.734346   favorite\n",
       "401  0.662333    pleased\n",
       "219  0.637845    friends\n",
       "320  0.604999       love\n",
       "555  0.592850        vet\n",
       "443  0.587811       rich\n",
       "239  0.586683      great"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df = pd.DataFrame(lr.coef_).T\n",
    "coef_df['word'] = list(tf_vectorizer.get_feature_names())\n",
    "coef_df.sort_values(0, ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### your turn\n",
    "\n",
    "Go back and spit our dataset into a training and test set. Run and test a model with a large vocabulary one one with a smaller vocabulary. How does fit on the test/train sets compare?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Rescaling the Data with tf-idf\n",
    "\\begin{equation*}\n",
    "\\text{tfidf}(w, d) = \\text{tf} \\log\\big(\\frac{N + 1}{N_w + 1}\\big) + 1\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "bards_words =[\"The fool doth think he is wise,\",\n",
    "              \"but the wise man knows himself to be a fool\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "vect.fit(bards_words)\n",
    "bag_of_words = vect.transform(bards_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>be</th>\n",
       "      <th>but</th>\n",
       "      <th>doth</th>\n",
       "      <th>fool</th>\n",
       "      <th>he</th>\n",
       "      <th>himself</th>\n",
       "      <th>is</th>\n",
       "      <th>knows</th>\n",
       "      <th>man</th>\n",
       "      <th>the</th>\n",
       "      <th>think</th>\n",
       "      <th>to</th>\n",
       "      <th>wise</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.425677</td>\n",
       "      <td>0.302873</td>\n",
       "      <td>0.425677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.425677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.302873</td>\n",
       "      <td>0.425677</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.302873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.364693</td>\n",
       "      <td>0.364693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.259482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364693</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364693</td>\n",
       "      <td>0.364693</td>\n",
       "      <td>0.259482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.364693</td>\n",
       "      <td>0.259482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         be       but      doth      fool        he   himself        is  \\\n",
       "0  0.000000  0.000000  0.425677  0.302873  0.425677  0.000000  0.425677   \n",
       "1  0.364693  0.364693  0.000000  0.259482  0.000000  0.364693  0.000000   \n",
       "\n",
       "      knows       man       the     think        to      wise  \n",
       "0  0.000000  0.000000  0.302873  0.425677  0.000000  0.302873  \n",
       "1  0.364693  0.364693  0.259482  0.000000  0.364693  0.259482  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame( bag_of_words.toarray(), columns=list(vect.get_feature_names()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(min_df=.01,\n",
    "                stop_words=\"english\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=0.01,\n",
       "        ngram_range=(1, 1), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words='english', strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect.fit(amazon_df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "tfidf = tfidf_vect.transform(amazon_df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(tfidf, amazon_df['Positive Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[11047,  7020],\n",
       "       [ 3933, 28000]])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print accuracy_score(amazon_df['Positive Review'], lr.predict(tfidf))\n",
    "confusion_matrix(amazon_df['Positive Review'], lr.predict(tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>5.056468</td>\n",
       "      <td>highly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4.999664</td>\n",
       "      <td>best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>4.663251</td>\n",
       "      <td>delicious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>4.626625</td>\n",
       "      <td>wonderful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>4.544307</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>4.377871</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.240002</td>\n",
       "      <td>amazing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>3.840702</td>\n",
       "      <td>excellent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>3.773116</td>\n",
       "      <td>perfect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>3.707800</td>\n",
       "      <td>loves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>3.509942</td>\n",
       "      <td>favorite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>3.442428</td>\n",
       "      <td>thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>3.436356</td>\n",
       "      <td>glad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3.304006</td>\n",
       "      <td>awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>2.801393</td>\n",
       "      <td>fantastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>2.685495</td>\n",
       "      <td>years</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>2.611909</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>2.518515</td>\n",
       "      <td>pleased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>2.479076</td>\n",
       "      <td>rich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>2.429870</td>\n",
       "      <td>friends</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       word\n",
       "257  5.056468     highly\n",
       "41   4.999664       best\n",
       "147  4.663251  delicious\n",
       "573  4.626625  wonderful\n",
       "239  4.544307      great\n",
       "320  4.377871       love\n",
       "18   4.240002    amazing\n",
       "183  3.840702  excellent\n",
       "393  3.773116    perfect\n",
       "322  3.707800      loves\n",
       "198  3.509942   favorite\n",
       "520  3.442428      thank\n",
       "229  3.436356       glad\n",
       "29   3.304006    awesome\n",
       "194  2.801393  fantastic\n",
       "583  2.685495      years\n",
       "246  2.611909      happy\n",
       "401  2.518515    pleased\n",
       "443  2.479076       rich\n",
       "219  2.429870    friends"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_df = pd.DataFrame(lr.coef_).T\n",
    "coef_df['word'] = list(tf_vectorizer.get_feature_names())\n",
    "coef_df.sort_values(0, ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Bag of words with more than one word (n-grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bards_words:\n",
      "['The fool doth think he is wise,', 'but the wise man knows himself to be a fool']\n"
     ]
    }
   ],
   "source": [
    "print(\"bards_words:\\n{}\".format(bards_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'be',\n",
       " u'be fool',\n",
       " u'but',\n",
       " u'but the',\n",
       " u'doth',\n",
       " u'doth think',\n",
       " u'fool',\n",
       " u'fool doth',\n",
       " u'he',\n",
       " u'he is',\n",
       " u'himself',\n",
       " u'himself to',\n",
       " u'is',\n",
       " u'is wise',\n",
       " u'knows',\n",
       " u'knows himself',\n",
       " u'man',\n",
       " u'man knows',\n",
       " u'the',\n",
       " u'the fool',\n",
       " u'the wise',\n",
       " u'think',\n",
       " u'think he',\n",
       " u'to',\n",
       " u'to be',\n",
       " u'wise',\n",
       " u'wise man']"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(bards_words)\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>be</th>\n",
       "      <th>be fool</th>\n",
       "      <th>but</th>\n",
       "      <th>but the</th>\n",
       "      <th>doth</th>\n",
       "      <th>doth think</th>\n",
       "      <th>fool</th>\n",
       "      <th>fool doth</th>\n",
       "      <th>he</th>\n",
       "      <th>he is</th>\n",
       "      <th>...</th>\n",
       "      <th>man knows</th>\n",
       "      <th>the</th>\n",
       "      <th>the fool</th>\n",
       "      <th>the wise</th>\n",
       "      <th>think</th>\n",
       "      <th>think he</th>\n",
       "      <th>to</th>\n",
       "      <th>to be</th>\n",
       "      <th>wise</th>\n",
       "      <th>wise man</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   be  be fool  but  but the  doth  doth think  fool  fool doth  he  he is  \\\n",
       "0   0        0    0        0     1           1     1          1   1      1   \n",
       "1   1        1    1        1     0           0     1          0   0      0   \n",
       "\n",
       "     ...     man knows  the  the fool  the wise  think  think he  to  to be  \\\n",
       "0    ...             0    1         1         0      1         1   0      0   \n",
       "1    ...             1    1         0         1      0         0   1      1   \n",
       "\n",
       "   wise  wise man  \n",
       "0     1         0  \n",
       "1     1         1  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words = vect.transform(bards_words)\n",
    "\n",
    "pd.DataFrame( bag_of_words.toarray(), columns=list(vect.get_feature_names()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'be',\n",
       " u'be fool',\n",
       " u'but',\n",
       " u'but the',\n",
       " u'but the wise',\n",
       " u'doth',\n",
       " u'doth think',\n",
       " u'doth think he',\n",
       " u'fool',\n",
       " u'fool doth',\n",
       " u'fool doth think',\n",
       " u'he',\n",
       " u'he is',\n",
       " u'he is wise',\n",
       " u'himself',\n",
       " u'himself to',\n",
       " u'himself to be',\n",
       " u'is',\n",
       " u'is wise',\n",
       " u'knows',\n",
       " u'knows himself',\n",
       " u'knows himself to',\n",
       " u'man',\n",
       " u'man knows',\n",
       " u'man knows himself',\n",
       " u'the',\n",
       " u'the fool',\n",
       " u'the fool doth',\n",
       " u'the wise',\n",
       " u'the wise man',\n",
       " u'think',\n",
       " u'think he',\n",
       " u'think he is',\n",
       " u'to',\n",
       " u'to be',\n",
       " u'to be fool',\n",
       " u'wise',\n",
       " u'wise man',\n",
       " u'wise man knows']"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,3))\n",
    "vect.fit(bards_words)\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best cross-validation score: 0.77\n",
      "Best parameters:\n",
      "{'tfidfvectorizer__ngram_range': (1, 1)}\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(TfidfVectorizer(min_df=.01,\n",
    "                                    stop_words = 'english'), \n",
    "                     LogisticRegression())\n",
    "#\n",
    "param_grid = {\"tfidfvectorizer__ngram_range\": [(1, 1), (1, 2), (1, 3)]}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=3)\n",
    "\n",
    "grid.fit(amazon_df['Text'], amazon_df['Positive Review'])\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid.best_score_))\n",
    "print(\"Best parameters:\\n{}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_tfidfvectorizer__ngram_range</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.77248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>0.77230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1, 3)</td>\n",
       "      <td>0.77218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_tfidfvectorizer__ngram_range  mean_test_score\n",
       "0                             (1, 1)          0.77248\n",
       "1                             (1, 2)          0.77230\n",
       "2                             (1, 3)          0.77218"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid.cv_results_)[['param_tfidfvectorizer__ngram_range','mean_test_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Cleaning Text on your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "string = '<br> Some random crap.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Some random crap.'"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.replace('<br>', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def clean_string(string):\n",
    "    clean_string = string.replace('<br>', '')\n",
    "    return clean_string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Some random crap.'"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_string('<br> Some random crap.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "amazon_df['clean_text'] = amazon_df['Text'].apply(clean_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    These are the best \"sugar free\" (non-enriched ...\n",
       "1    I buy this regularly at Whole Foods for about ...\n",
       "2    Mori-Nu Tofu, Lite, Silken, Firm, 12.3-Ounce B...\n",
       "3    I usually don't particularly like shortbread c...\n",
       "4    This is good for people that have to be on a s...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df['clean_text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def clean_string(string):\n",
    "    clean_string = string.replace('<br>', '')\n",
    "    clean_string = clean_string.replace(\"n't\", \" not\")\n",
    "    return clean_string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def clean_string(string):\n",
    "    clean_string = string.replace('<br>', '')\n",
    "    clean_string = clean_string.replace(\"n't\", \" not\")\n",
    "    \n",
    "    clean_sentence = ''\n",
    "    for word in clean_string.split():\n",
    "        word = word.strip('!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~')\n",
    "        clean_sentence =clean_sentence + ' ' + word\n",
    "    return clean_sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Did that work'"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_string('Did! that work?<br>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'dog'"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('dogs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'dog'"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'bark'"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('barking')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def clean_string(string):\n",
    "    clean_string = string.replace('<br>', '')\n",
    "    clean_string = clean_string.replace(\"n't\", \" not\")\n",
    "    \n",
    "    clean_sentence = u''\n",
    "    for word in clean_string.split():\n",
    "        word = word.strip('!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~')\n",
    "        try:\n",
    "            word = stemmer.stem(word)\n",
    "        except:\n",
    "            word = word\n",
    "        try:\n",
    "            clean_sentence =clean_sentence + ' ' + word\n",
    "        except:\n",
    "            print word\n",
    "    return clean_sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u' the dog went run with other dog'"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_string('The dog went running with other dogs.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organic\n",
      "185F\n",
      "185F\n",
      "\n",
      "105F\n",
      "ENERGY\n",
      "Typhoo\n",
      "Salt\n",
      "brl&eacute;e\n",
      "brl&eacute;e\n",
      "Quaker\n",
      "href=\"http://www.amazon.com/gp/product/B004KJXSHO\">Keurig\n",
      "\n",
      "Brand\n",
      "Brand\n",
      "Marzano\n",
      "pt&eacute\n",
      "pt&eacute\n",
      "aykur\n",
      "90\n",
      "2\n",
      "7-year-old\n",
      "7-year-old\n",
      "2\n",
      "1\n",
      "ENERGY\n",
      "60/k-cup\n",
      "AvoDerm\n",
      "AvoDerm\n",
      "AvoDerm\n",
      "AvoDerm\n",
      "AvoDerm\n",
      "58\n",
      "ENERGY\n",
      "ENERGY\n",
      "Eatin'\n",
      "\n",
      "99\n",
      "\n",
      "Mountain\n",
      "VIA\n",
      "96\n",
      "12\n",
      "6\n",
      "8\n",
      "1.37\n",
      "barbecue\n",
      "thinkThin\n",
      "thinkThin\n",
      "Eatin'\n",
      "104\n",
      "400\n",
      "200\n",
      "180\n",
      "103\n",
      "\n",
      "pt&eacute\n",
      "Rverie\n",
      "s\n",
      "DecoBros</a\n",
      "Kelloggs\n",
      "href=\"http://www.amazon.com/gp/product/B000G72D70\">swissgold\n",
      "500\n",
      "350\n",
      "Organic\n",
      "\n",
      "\n",
      "1\n",
      "8-ounce\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "400.<br\n",
      "Water\n",
      "Jel\n",
      "Jel\n",
      "Jel\n",
      "Jel\n",
      "Jel\n",
      "Jel\n",
      "\n",
      "\n",
      "OwnOrganics\n",
      "Nol\n",
      "Foods,\n",
      "AUTOSPOUT\n",
      "ENERGY\n",
      "VIA\n",
      "\n",
      "\n",
      "113F\n",
      "113F\n",
      "50F.<br\n",
      "Nioise\n",
      "VIA\n",
      "ENERGY\n",
      "Own\n",
      "\n",
      "ENERGY\n",
      "brl&eacute;e\n",
      "\n",
      "2010\n",
      "Almond\n",
      "NutraSweet/aspartame\n",
      "175\n",
      "\n",
      "\n",
      "ENERGY\n",
      "Gold\n",
      "pt&eacute\n",
      "WellPet\n",
      "WELLNESS\n",
      "WELLNESS\n",
      "Program\n",
      "ENERGY\n",
      "href=\"http://www.amazon.com/gp/product/B002WWVDK0\">Sexergy\n",
      "Starbucks\n",
      "Caribou\n",
      "Coffee\n",
      "House\n",
      "Folgers\n",
      "O'Clock\n",
      "Starbucks\n",
      "Caribou\n",
      "Coffee\n",
      "Mountain\n",
      "VIA\n",
      "25\n",
      "OwnOrganics\n",
      "Brand\n",
      "Brand\n",
      "ENERGY\n",
      "ENERGY\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     these are the best sugar free non-enrich whea...\n",
       "1     i buy this regular at whole food for about 30...\n",
       "2     mori-nu tofu lite silken firm 12.3-ounc box p...\n",
       "3     i usual do not particular like shortbread coo...\n",
       "4     this is good for peopl that have to be on a s...\n",
       "5     my uncl bilbo alway woke up to a hearti bowl ...\n",
       "6     this is the herbal remedi of choic for those ...\n",
       "7     just receiv these today and was stun to see t...\n",
       "8     best coffe ever after tast these fresh ground...\n",
       "9     i have been buy ella sinc my son was 6 month ...\n",
       "Name: clean_text, dtype: object"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df['clean_text'] = amazon_df['Text'].apply(clean_string)\n",
    "\n",
    "amazon_df['clean_text'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,1), min_df=.01, max_df=.5, stop_words = 'english')\n",
    "vect.fit(amazon_df['clean_text'])\n",
    "\n",
    "clean_tf = vect.transform(amazon_df['clean_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(clean_tf, amazon_df['Positive Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7876\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[10755,  7312],\n",
       "       [ 3308, 28625]])"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print accuracy_score(amazon_df['Positive Review'], lr.predict(clean_tf))\n",
    "confusion_matrix(amazon_df['Positive Review'], lr.predict(clean_tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Naive Bayes\n",
    "\n",
    "$$\n",
    "\\frac{P(L_1~|~{\\rm features})}{P(L_2~|~{\\rm features})} = \\frac{P({\\rm features}~|~L_1)}{P({\\rm features}~|~L_2)}\\frac{P(L_1)}{P(L_2)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(min_df=.01, \n",
    "                                stop_words=\"english\").fit(amazon_df['Text'])\n",
    "\n",
    "X_train_tf = tf_vectorizer.transform(amazon_df['Text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train_tf, amazon_df['Positive Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 5908, 12159],\n",
       "       [ 1146, 30787]])"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print accuracy_score(amazon_df['Positive Review'], nb.predict(tfidf))\n",
    "confusion_matrix(amazon_df['Positive Review'], nb.predict(tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>-3.739278</td>\n",
       "      <td>-3.992257</td>\n",
       "      <td>br</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>-5.162631</td>\n",
       "      <td>-4.347369</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>-5.434581</td>\n",
       "      <td>-4.526610</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>-4.507674</td>\n",
       "      <td>-4.589347</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>-4.335316</td>\n",
       "      <td>-4.624931</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>-4.862358</td>\n",
       "      <td>-4.640573</td>\n",
       "      <td>tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>-4.489168</td>\n",
       "      <td>-4.655693</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>-4.565865</td>\n",
       "      <td>-4.735544</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>-4.744796</td>\n",
       "      <td>-4.811386</td>\n",
       "      <td>just</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>-4.513256</td>\n",
       "      <td>-4.847411</td>\n",
       "      <td>taste</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1     word\n",
       "58  -3.739278 -3.992257       br\n",
       "239 -5.162631 -4.347369    great\n",
       "320 -5.434581 -4.526610     love\n",
       "235 -4.507674 -4.589347     good\n",
       "303 -4.335316 -4.624931     like\n",
       "515 -4.862358 -4.640573      tea\n",
       "101 -4.489168 -4.655693   coffee\n",
       "415 -4.565865 -4.735544  product\n",
       "286 -4.744796 -4.811386     just\n",
       "510 -4.513256 -4.847411    taste"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_probs = pd.DataFrame(nb.feature_log_prob_).T\n",
    "nb_probs['word'] = tf_vectorizer.get_feature_names()\n",
    "nb_probs.sort_values(1, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>-3.739278</td>\n",
       "      <td>-3.992257</td>\n",
       "      <td>br</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>-4.335316</td>\n",
       "      <td>-4.624931</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>-4.489168</td>\n",
       "      <td>-4.655693</td>\n",
       "      <td>coffee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>-4.507674</td>\n",
       "      <td>-4.589347</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>-4.513256</td>\n",
       "      <td>-4.847411</td>\n",
       "      <td>taste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>-4.565865</td>\n",
       "      <td>-4.735544</td>\n",
       "      <td>product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>-4.695297</td>\n",
       "      <td>-4.858587</td>\n",
       "      <td>flavor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>-4.744796</td>\n",
       "      <td>-4.811386</td>\n",
       "      <td>just</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>-4.862358</td>\n",
       "      <td>-4.640573</td>\n",
       "      <td>tea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>-5.069015</td>\n",
       "      <td>-5.375158</td>\n",
       "      <td>don</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1     word\n",
       "58  -3.739278 -3.992257       br\n",
       "303 -4.335316 -4.624931     like\n",
       "101 -4.489168 -4.655693   coffee\n",
       "235 -4.507674 -4.589347     good\n",
       "510 -4.513256 -4.847411    taste\n",
       "415 -4.565865 -4.735544  product\n",
       "208 -4.695297 -4.858587   flavor\n",
       "286 -4.744796 -4.811386     just\n",
       "515 -4.862358 -4.640573      tea\n",
       "163 -5.069015 -5.375158      don"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_probs.sort_values(0, ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Topic Modeling and Document Clustering\n",
    "#### Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vect = CountVectorizer(max_features=5000, \n",
    "                       max_df=.5,\n",
    "                       stop_words = 'english', \n",
    "                      min_df = .01)\n",
    "\n",
    "X_train = vect.fit_transform(amazon_df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda_model = LatentDirichletAllocation(n_topics=10,\n",
    "                                      learning_method = 'batch',\n",
    "                                      max_iter=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='batch', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=25, mean_change_tol=0.001,\n",
       "             n_jobs=1, n_topics=10, perp_tol=0.1, random_state=None,\n",
       "             topic_word_prior=None, total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "document_topics = lda_model.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lda.components_.shape: (10, 586)\n"
     ]
    }
   ],
   "source": [
    "print(\"lda.components_.shape: {}\".format(lda_model.components_.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag, treats, chips, dog, like, treat, dogs, just, size, small\n",
      "br, product, amazon, com, www, http, gp, href, pack, ounce\n",
      "amazon, product, price, order, store, great, buy, box, good, ordered\n",
      "like, flavor, taste, just, good, drink, really, sweet, flavors, sugar\n",
      "food, cat, dog, cats, eat, old, like, chicken, foods, loves\n",
      "use, water, product, just, like, great, make, oil, salt, butter\n",
      "great, free, snack, good, gluten, love, bars, healthy, fat, eat\n",
      "tea, green, teas, flavor, black, like, drink, taste, ginger, good\n",
      "coffee, cup, like, cups, flavor, good, taste, strong, blend, beans\n",
      "chocolate, like, taste, cookies, good, milk, hot, sauce, flavor, just\n",
      "yummy, yes, years, year, www, wrong, wouldn, worth, world, works\n"
     ]
    }
   ],
   "source": [
    "tm_df = pd.DataFrame(lda_model.components_).T\n",
    "tm_df['words'] = vect.get_feature_names()\n",
    "for k in tm_df.keys():\n",
    "    print ', '.join(tm_df.sort_values(by=k, ascending=False)['words'].tolist()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(document_topics, amazon_df['Positive Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64106\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1682, 16385],\n",
       "       [ 1562, 30371]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print accuracy_score(amazon_df['Positive Review'], lr.predict(document_topics))\n",
    "confusion_matrix(amazon_df['Positive Review'], lr.predict(document_topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7,\n",
       "             learning_method='batch', learning_offset=10.0,\n",
       "             max_doc_update_iter=100, max_iter=25, mean_change_tol=0.001,\n",
       "             n_jobs=1, n_topics=50, perp_tol=0.1, random_state=None,\n",
       "             topic_word_prior=None, total_samples=1000000.0, verbose=0)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model_50 = LatentDirichletAllocation(n_topics=50,\n",
    "                                      learning_method = 'batch',\n",
    "                                      max_iter=25)\n",
    "lda_model_50.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_topics_50 = lda_model_50.transform(X_train)\n",
    "\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "lr.fit(document_topics_50, amazon_df['Positive Review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 7002, 11065],\n",
       "       [ 3930, 28003]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print accuracy_score(amazon_df['Positive Review'], lr.predict(document_topics_50))\n",
    "confusion_matrix(amazon_df['Positive Review'], lr.predict(document_topics_50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "popcorn, corn, packs, pop, bowl, just, great, like, taste, use\n",
      "bottle, energy, red, powder, bottles, drinks, gives, oz, drink, caffeine\n",
      "food, dog, foods, dry, feed, ingredients, pet, dogs, quality, diet\n",
      "eat, food, cats, cat, chicken, like, picky, ate, eats, just\n",
      "product, recommend, highly, great, excellent, recommended, good, taste, love, definitely\n",
      "products, quality, company, fast, product, items, service, high, shipping, delivery\n",
      "tea, teas, drink, like, good, cup, taste, iced, flavor, love\n",
      "bought, try, reviews, great, thought, decided, read, thanks, fantastic, did\n",
      "use, oil, coconut, cooking, cook, great, recipe, used, love, taste\n",
      "vanilla, beans, ground, starbucks, french, coffee, aroma, taste, flavored, smell\n",
      "chocolate, dark, cocoa, hot, milk, rich, taste, sweet, like, best\n",
      "green, white, black, caffeine, color, decaf, mild, high, fresh, compared\n",
      "low, diet, pasta, version, regular, alternative, jar, calorie, difference, great\n",
      "coffee, blend, strong, roast, bold, like, bitter, smooth, taste, dark\n",
      "chips, potato, chip, bag, like, good, taste, flavor, crunch, great\n",
      "product, using, used, use, works, ve, does, just, don, like\n",
      "organic, rice, brown, color, non, foods, texture, tasty, delicious, comes\n",
      "ingredients, natural, cinnamon, soy, ingredient, list, contains, contain, label, artificial\n",
      "salt, salty, pepper, fish, formula, taste, sodium, use, just, love\n",
      "weight, help, problems, stomach, started, teeth, blue, vet, issues, recommended\n",
      "dog, treats, dogs, treat, loves, love, chew, small, like, great\n",
      "cat, cans, canned, seen, case, grain, ve, food, care, formula\n",
      "sweet, taste, honey, like, liked, flavor, good, stars, bit, light\n",
      "br, review, ll, want, people, note, just, new, thing, know\n",
      "add, milk, cream, ice, make, cold, mix, just, adding, half\n",
      "years, old, year, ve, ago, months, month, past, new, couple\n",
      "order, ordered, received, amazon, arrived, product, item, time, box, ordering\n",
      "like, taste, don, good, just, really, bad, tastes, think, know\n",
      "flavor, flavored, fan, nice, original, good, favorite, big, strong, try\n",
      "free, mix, gluten, bread, wheat, good, baking, make, best, products\n",
      "price, great, amazon, save, good, deal, shipping, subscribe, cost, buy\n",
      "tried, love, flavors, ve, favorite, different, best, variety, absolutely, try\n",
      "fruit, juice, syrup, ginger, lemon, apple, dried, like, taste, sweet\n",
      "cookies, perfect, cookie, kids, soft, love, just, great, like, taste\n",
      "box, bag, package, open, packaging, small, size, plastic, inside, opened\n",
      "store, amazon, local, stores, grocery, buy, available, love, online, stock\n",
      "snack, bars, healthy, bar, great, protein, good, eat, kind, taste\n",
      "sauce, hot, spicy, spice, heat, like, just, good, flavor, great\n",
      "amazon, pack, com, product, www, http, gp, href, ounce, 12\n",
      "time, long, candy, loved, family, hard, gift, friends, great, goes\n",
      "bags, buy, buying, bag, money, bought, pound, size, bulk, waste\n",
      "sugar, jerky, beef, meat, real, sweet, texture, added, like, pieces\n",
      "cereal, loves, baby, son, daughter, wife, oatmeal, husband, likes, breakfast\n",
      "butter, peanut, soup, nuts, creamy, like, great, eat, good, texture\n",
      "day, just, got, days, took, didn, night, time, start, little\n",
      "calories, fat, serving, fiber, high, low, sodium, protein, crackers, content\n",
      "coffee, cup, cups, keurig, machine, good, use, maker, instant, great\n",
      "water, drink, drinking, taste, hot, day, tastes, just, added, bottle\n",
      "easy, cheese, make, minutes, just, little, cut, quick, time, makes\n",
      "brand, stuff, best, better, good, brands, ve, tried, expensive, far\n",
      "yummy, yes, years, year, www, wrong, wouldn, worth, world, works\n"
     ]
    }
   ],
   "source": [
    "tm_df = pd.DataFrame(lda_model_50.components_).T\n",
    "tm_df['words'] = vect.get_feature_names()\n",
    "for k in tm_df.keys():\n",
    "    print ', '.join(tm_df.sort_values(by=k, ascending=False)['words'].tolist()[:10])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
